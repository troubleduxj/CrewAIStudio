# CrewAI Studio Êï∞ÊçÆÂ∫ìËÆæËÆ°ÊñáÊ°£

## üìã ÊñáÊ°£Ê¶ÇËø∞

Êú¨ÊñáÊ°£ËØ¶ÁªÜÊèèËø∞‰∫Ü CrewAI Studio È°πÁõÆÁöÑÊï∞ÊçÆÂ∫ìËÆæËÆ°ÔºåÂåÖÊã¨Êï∞ÊçÆÊ®°Âûã„ÄÅÂÖ≥Á≥ªÂõæ„ÄÅÁ¥¢ÂºïÁ≠ñÁï•„ÄÅÁ∫¶ÊùüËßÑÂàôÂíåÊï∞ÊçÆËøÅÁßªÊñπÊ°à„ÄÇ

---

## üèóÔ∏è Êï∞ÊçÆÂ∫ìÊû∂ÊûÑÊ¶ÇËßà

### ÊäÄÊúØÊ†à
- **Êï∞ÊçÆÂ∫ìÂºïÊìé**: PostgreSQL 14+
- **ORMÊ°ÜÊû∂**: SQLAlchemy 2.0
- **ËøÅÁßªÂ∑•ÂÖ∑**: Alembic
- **ËøûÊé•Ê±†**: SQLAlchemy Pool
- **Â§á‰ªΩÁ≠ñÁï•**: pg_dump + ÂÆöÊó∂Â§á‰ªΩ

### Êï∞ÊçÆÂ∫ìÂëΩÂêçËßÑËåÉ
- **Ë°®Âêç**: Â∞èÂÜôÂ≠óÊØç + ‰∏ãÂàíÁ∫øÔºåÂ§çÊï∞ÂΩ¢Âºè (Â¶Ç: `agents`, `tasks`)
- **Â≠óÊÆµÂêç**: Â∞èÂÜôÂ≠óÊØç + ‰∏ãÂàíÁ∫ø (Â¶Ç: `created_at`, `max_execution_time`)
- **Á¥¢ÂºïÂêç**: `idx_{table}_{column(s)}` (Â¶Ç: `idx_agents_status`)
- **Â§ñÈîÆÂêç**: `fk_{table}_{referenced_table}_{column}` (Â¶Ç: `fk_tasks_agents_agent_id`)
- **Á∫¶ÊùüÂêç**: `ck_{table}_{constraint_desc}` (Â¶Ç: `ck_agents_status_valid`)

---

## üìä Ê†∏ÂøÉÊï∞ÊçÆÊ®°Âûã

### 1. Âü∫Á°ÄÊ®°Âûã (BaseModel)

```sql
-- ÊâÄÊúâË°®ÁöÑÂü∫Á°ÄÂ≠óÊÆµ
CREATE TABLE base_fields (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**Â≠óÊÆµËØ¥Êòé**:
- `id`: ‰∏ªÈîÆÔºå‰ΩøÁî®UUIDÁ°Æ‰øùÂÖ®Â±ÄÂîØ‰∏ÄÊÄß
- `created_at`: ÂàõÂª∫Êó∂Èó¥ÔºåÂ∏¶Êó∂Âå∫‰ø°ÊÅØ
- `updated_at`: Êõ¥Êñ∞Êó∂Èó¥ÔºåËá™Âä®Êõ¥Êñ∞

### 2. ‰ª£ÁêÜÊ®°Âûã (Agent)

```sql
CREATE TABLE agents (
    -- Âü∫Á°ÄÂ≠óÊÆµ
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    
    -- Âü∫Êú¨‰ø°ÊÅØ
    name VARCHAR(255) NOT NULL,
    description TEXT,
    role VARCHAR(255) NOT NULL,
    goal TEXT NOT NULL,
    backstory TEXT,
    
    -- Á±ªÂûãÂíåÁä∂ÊÄÅ
    type VARCHAR(50) DEFAULT 'STANDARD',
    status VARCHAR(20) DEFAULT 'ACTIVE' CHECK (status IN ('ACTIVE', 'INACTIVE', 'TRAINING', 'ERROR')),
    
    -- LLMÈÖçÁΩÆ
    llm_config JSONB DEFAULT '{}',
    model VARCHAR(100),
    temperature DECIMAL(3,2) DEFAULT 0.7 CHECK (temperature >= 0 AND temperature <= 2),
    max_tokens INTEGER DEFAULT 1000 CHECK (max_tokens > 0),
    
    -- Â∑•ÂÖ∑ÂíåËÉΩÂäõ
    tools JSONB DEFAULT '[]',
    capabilities JSONB DEFAULT '[]',
    
    -- ÊâßË°åÈÖçÁΩÆ
    max_execution_time INTEGER DEFAULT 300 CHECK (max_execution_time > 0),
    allow_delegation BOOLEAN DEFAULT false,
    verbose BOOLEAN DEFAULT false,
    
    -- ÊèêÁ§∫ËØç
    system_prompt TEXT,
    custom_prompts JSONB DEFAULT '{}',
    
    -- ÊÄßËÉΩÁªüËÆ°
    total_executions INTEGER DEFAULT 0,
    successful_executions INTEGER DEFAULT 0,
    failed_executions INTEGER DEFAULT 0,
    avg_execution_time DECIMAL(10,2) DEFAULT 0,
    
    -- Á∫¶Êùü
    CONSTRAINT ck_agents_temperature_range CHECK (temperature >= 0 AND temperature <= 2),
    CONSTRAINT ck_agents_execution_stats CHECK (
        total_executions >= 0 AND 
        successful_executions >= 0 AND 
        failed_executions >= 0 AND
        successful_executions + failed_executions <= total_executions
    )
);
```

### 3. ‰ªªÂä°Ê®°Âûã (Task)

```sql
CREATE TABLE tasks (
    -- Âü∫Á°ÄÂ≠óÊÆµ
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    
    -- Âü∫Êú¨‰ø°ÊÅØ
    name VARCHAR(255) NOT NULL,
    description TEXT NOT NULL,
    type VARCHAR(50) DEFAULT 'STANDARD',
    
    -- Áä∂ÊÄÅÁÆ°ÁêÜ
    status VARCHAR(20) DEFAULT 'PENDING' CHECK (
        status IN ('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', 'PAUSED')
    ),
    priority INTEGER DEFAULT 5 CHECK (priority >= 1 AND priority <= 10),
    
    -- Êï∞ÊçÆ
    input_data JSONB DEFAULT '{}',
    output_data JSONB DEFAULT '{}',
    context JSONB DEFAULT '{}',
    
    -- ÊâßË°åÈÖçÁΩÆ
    max_execution_time INTEGER DEFAULT 300 CHECK (max_execution_time > 0),
    retry_count INTEGER DEFAULT 0 CHECK (retry_count >= 0),
    max_retries INTEGER DEFAULT 3 CHECK (max_retries >= 0),
    
    -- ÂÖ≥ËÅî
    assigned_agent_id UUID REFERENCES agents(id) ON DELETE SET NULL,
    parent_task_id UUID REFERENCES tasks(id) ON DELETE CASCADE,
    workflow_id UUID, -- Â§ñÈîÆÂ∞ÜÂú®workflowË°®ÂàõÂª∫ÂêéÊ∑ªÂä†
    
    -- ‰æùËµñÂÖ≥Á≥ª
    dependencies JSONB DEFAULT '[]', -- Â≠òÂÇ®‰æùËµñ‰ªªÂä°ÁöÑIDÊï∞ÁªÑ
    
    -- ÊâßË°å‰ø°ÊÅØ
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    execution_time DECIMAL(10,2),
    error_message TEXT,
    logs JSONB DEFAULT '[]',
    
    -- Ê†áÁ≠æÂíåÂÖÉÊï∞ÊçÆ
    tags JSONB DEFAULT '[]',
    metadata JSONB DEFAULT '{}',
    
    -- Á∫¶Êùü
    CONSTRAINT ck_tasks_execution_time_positive CHECK (execution_time >= 0),
    CONSTRAINT ck_tasks_completion_logic CHECK (
        (status = 'COMPLETED' AND completed_at IS NOT NULL) OR
        (status != 'COMPLETED' AND (completed_at IS NULL OR completed_at IS NOT NULL))
    ),
    CONSTRAINT ck_tasks_start_complete_order CHECK (
        started_at IS NULL OR completed_at IS NULL OR started_at <= completed_at
    )
);
```

### 4. Â∑•‰ΩúÊµÅÊ®°Âûã (Workflow)

```sql
CREATE TABLE workflows (
    -- Âü∫Á°ÄÂ≠óÊÆµ
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    
    -- Âü∫Êú¨‰ø°ÊÅØ
    name VARCHAR(255) NOT NULL,
    description TEXT,
    version VARCHAR(50) DEFAULT '1.0.0',
    
    -- Áä∂ÊÄÅÂíåÁ±ªÂûã
    status VARCHAR(20) DEFAULT 'DRAFT' CHECK (
        status IN ('DRAFT', 'ACTIVE', 'INACTIVE', 'ARCHIVED')
    ),
    type VARCHAR(50) DEFAULT 'SEQUENTIAL',
    execution_mode VARCHAR(20) DEFAULT 'SYNC' CHECK (
        execution_mode IN ('SYNC', 'ASYNC')
    ),
    
    -- Â∑•‰ΩúÊµÅÂÆö‰πâ
    workflow_definition JSONB NOT NULL DEFAULT '{}',
    
    -- ÈÖçÁΩÆ
    agent_configs JSONB DEFAULT '{}',
    task_configs JSONB DEFAULT '{}',
    
    -- ÊâßË°åÈÖçÁΩÆ
    max_execution_time INTEGER DEFAULT 1800 CHECK (max_execution_time > 0),
    retry_policy JSONB DEFAULT '{"max_retries": 3, "retry_delay": 5}',
    error_handling VARCHAR(20) DEFAULT 'STOP' CHECK (
        error_handling IN ('STOP', 'CONTINUE', 'RETRY')
    ),
    
    -- Ë∞ÉÂ∫¶ÈÖçÁΩÆ
    scheduling JSONB DEFAULT '{}',
    trigger_conditions JSONB DEFAULT '{}',
    
    -- ÊâßË°åÁä∂ÊÄÅ
    current_step INTEGER DEFAULT 0,
    total_steps INTEGER DEFAULT 0,
    
    -- ÁªüËÆ°‰ø°ÊÅØ
    total_executions INTEGER DEFAULT 0,
    successful_executions INTEGER DEFAULT 0,
    failed_executions INTEGER DEFAULT 0,
    avg_execution_time DECIMAL(10,2) DEFAULT 0,
    
    -- Ê†áÁ≠æÂíåÂÖÉÊï∞ÊçÆ
    tags JSONB DEFAULT '[]',
    metadata JSONB DEFAULT '{}',
    
    -- Á∫¶Êùü
    CONSTRAINT ck_workflows_step_range CHECK (
        current_step >= 0 AND current_step <= total_steps
    ),
    CONSTRAINT ck_workflows_execution_stats CHECK (
        total_executions >= 0 AND 
        successful_executions >= 0 AND 
        failed_executions >= 0 AND
        successful_executions + failed_executions <= total_executions
    )
);

-- Ê∑ªÂä†workflowÂ§ñÈîÆÂà∞tasksË°®
ALTER TABLE tasks ADD CONSTRAINT fk_tasks_workflows_workflow_id 
    FOREIGN KEY (workflow_id) REFERENCES workflows(id) ON DELETE CASCADE;
```

### 5. ÊâßË°åËÆ∞ÂΩïÊ®°Âûã (Execution)

```sql
CREATE TABLE executions (
    -- Âü∫Á°ÄÂ≠óÊÆµ
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    
    -- ÊâßË°åÁ±ªÂûã
    execution_type VARCHAR(20) NOT NULL CHECK (
        execution_type IN ('AGENT', 'TASK', 'WORKFLOW')
    ),
    
    -- ÂÖ≥ËÅîÂÆû‰Ωì
    agent_id UUID REFERENCES agents(id) ON DELETE CASCADE,
    task_id UUID REFERENCES tasks(id) ON DELETE CASCADE,
    workflow_id UUID REFERENCES workflows(id) ON DELETE CASCADE,
    
    -- ÊâßË°åÁä∂ÊÄÅ
    status VARCHAR(20) DEFAULT 'PENDING' CHECK (
        status IN ('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', 'TIMEOUT')
    ),
    
    -- ÊâßË°åÊï∞ÊçÆ
    input_data JSONB DEFAULT '{}',
    output_data JSONB DEFAULT '{}',
    context JSONB DEFAULT '{}',
    
    -- Êó∂Èó¥‰ø°ÊÅØ
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    execution_time DECIMAL(10,2),
    timeout_at TIMESTAMP WITH TIME ZONE,
    
    -- ÈîôËØØ‰ø°ÊÅØ
    error_code VARCHAR(50),
    error_message TEXT,
    error_details JSONB DEFAULT '{}',
    
    -- ÊâßË°åÊó•Âøó
    logs JSONB DEFAULT '[]',
    
    -- ÊÄßËÉΩÊåáÊ†á
    cpu_usage DECIMAL(5,2),
    memory_usage DECIMAL(10,2),
    
    -- ÂÖÉÊï∞ÊçÆ
    metadata JSONB DEFAULT '{}',
    
    -- Á∫¶Êùü
    CONSTRAINT ck_executions_entity_reference CHECK (
        (execution_type = 'AGENT' AND agent_id IS NOT NULL AND task_id IS NULL AND workflow_id IS NULL) OR
        (execution_type = 'TASK' AND task_id IS NOT NULL AND agent_id IS NULL AND workflow_id IS NULL) OR
        (execution_type = 'WORKFLOW' AND workflow_id IS NOT NULL AND agent_id IS NULL AND task_id IS NULL)
    ),
    CONSTRAINT ck_executions_time_logic CHECK (
        started_at IS NULL OR completed_at IS NULL OR started_at <= completed_at
    ),
    CONSTRAINT ck_executions_execution_time_positive CHECK (execution_time >= 0)
);
```

### 6. ‰ªªÂä°‰æùËµñÂÖ≥Á≥ªË°® (Task Dependencies)

```sql
CREATE TABLE task_dependencies (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    
    -- ‰æùËµñÂÖ≥Á≥ª
    task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
    depends_on_task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
    
    -- ‰æùËµñÁ±ªÂûã
    dependency_type VARCHAR(20) DEFAULT 'FINISH_TO_START' CHECK (
        dependency_type IN ('FINISH_TO_START', 'START_TO_START', 'FINISH_TO_FINISH', 'START_TO_FINISH')
    ),
    
    -- Á∫¶Êùü
    CONSTRAINT ck_task_deps_no_self_reference CHECK (task_id != depends_on_task_id),
    CONSTRAINT uk_task_dependencies UNIQUE (task_id, depends_on_task_id)
);
```

---

## üîó ÂÆû‰ΩìÂÖ≥Á≥ªÂõæ

```mermaid
erDiagram
    AGENTS {
        uuid id PK
        varchar name
        text description
        varchar role
        text goal
        text backstory
        varchar type
        varchar status
        jsonb llm_config
        varchar model
        decimal temperature
        integer max_tokens
        jsonb tools
        jsonb capabilities
        integer max_execution_time
        boolean allow_delegation
        boolean verbose
        text system_prompt
        jsonb custom_prompts
        timestamp created_at
        timestamp updated_at
    }
    
    TASKS {
        uuid id PK
        varchar name
        text description
        varchar type
        varchar status
        integer priority
        jsonb input_data
        jsonb output_data
        jsonb context
        integer max_execution_time
        integer retry_count
        integer max_retries
        uuid assigned_agent_id FK
        uuid parent_task_id FK
        uuid workflow_id FK
        jsonb dependencies
        timestamp started_at
        timestamp completed_at
        decimal execution_time
        text error_message
        jsonb logs
        jsonb tags
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }
    
    WORKFLOWS {
        uuid id PK
        varchar name
        text description
        varchar version
        varchar status
        varchar type
        varchar execution_mode
        jsonb workflow_definition
        jsonb agent_configs
        jsonb task_configs
        integer max_execution_time
        jsonb retry_policy
        varchar error_handling
        jsonb scheduling
        jsonb trigger_conditions
        integer current_step
        integer total_steps
        integer total_executions
        integer successful_executions
        integer failed_executions
        decimal avg_execution_time
        jsonb tags
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }
    
    EXECUTIONS {
        uuid id PK
        varchar execution_type
        uuid agent_id FK
        uuid task_id FK
        uuid workflow_id FK
        varchar status
        jsonb input_data
        jsonb output_data
        jsonb context
        timestamp started_at
        timestamp completed_at
        decimal execution_time
        timestamp timeout_at
        varchar error_code
        text error_message
        jsonb error_details
        jsonb logs
        decimal cpu_usage
        decimal memory_usage
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }
    
    TASK_DEPENDENCIES {
        uuid id PK
        uuid task_id FK
        uuid depends_on_task_id FK
        varchar dependency_type
        timestamp created_at
    }
    
    AGENTS ||--o{ TASKS : "assigned_to"
    WORKFLOWS ||--o{ TASKS : "contains"
    TASKS ||--o{ TASKS : "parent_child"
    TASKS ||--o{ TASK_DEPENDENCIES : "has_dependencies"
    TASKS ||--o{ TASK_DEPENDENCIES : "depended_by"
    AGENTS ||--o{ EXECUTIONS : "executes"
    TASKS ||--o{ EXECUTIONS : "executes"
    WORKFLOWS ||--o{ EXECUTIONS : "executes"
```

---

## üìà Á¥¢ÂºïÁ≠ñÁï•

### 1. ‰∏ªÈîÆÁ¥¢Âºï (Ëá™Âä®ÂàõÂª∫)
```sql
-- ÊâÄÊúâË°®ÁöÑ‰∏ªÈîÆÁ¥¢ÂºïËá™Âä®ÂàõÂª∫
-- PRIMARY KEY indexes are automatically created
```

### 2. Â§ñÈîÆÁ¥¢Âºï
```sql
-- TasksË°®Â§ñÈîÆÁ¥¢Âºï
CREATE INDEX idx_tasks_assigned_agent_id ON tasks(assigned_agent_id);
CREATE INDEX idx_tasks_parent_task_id ON tasks(parent_task_id);
CREATE INDEX idx_tasks_workflow_id ON tasks(workflow_id);

-- ExecutionsË°®Â§ñÈîÆÁ¥¢Âºï
CREATE INDEX idx_executions_agent_id ON executions(agent_id);
CREATE INDEX idx_executions_task_id ON executions(task_id);
CREATE INDEX idx_executions_workflow_id ON executions(workflow_id);

-- Task DependenciesË°®Â§ñÈîÆÁ¥¢Âºï
CREATE INDEX idx_task_deps_task_id ON task_dependencies(task_id);
CREATE INDEX idx_task_deps_depends_on_task_id ON task_dependencies(depends_on_task_id);
```

### 3. Áä∂ÊÄÅÂíåÊü•ËØ¢Á¥¢Âºï
```sql
-- Áä∂ÊÄÅÁ¥¢Âºï
CREATE INDEX idx_agents_status ON agents(status);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_workflows_status ON workflows(status);
CREATE INDEX idx_executions_status ON executions(status);

-- Êó∂Èó¥Á¥¢Âºï
CREATE INDEX idx_agents_created_at ON agents(created_at);
CREATE INDEX idx_tasks_created_at ON tasks(created_at);
CREATE INDEX idx_workflows_created_at ON workflows(created_at);
CREATE INDEX idx_executions_created_at ON executions(created_at);
CREATE INDEX idx_executions_started_at ON executions(started_at);
CREATE INDEX idx_executions_completed_at ON executions(completed_at);

-- Â§çÂêàÁ¥¢Âºï
CREATE INDEX idx_tasks_status_priority ON tasks(status, priority DESC);
CREATE INDEX idx_executions_type_status ON executions(execution_type, status);
CREATE INDEX idx_tasks_agent_status ON tasks(assigned_agent_id, status);
```

### 4. JSONBÂ≠óÊÆµÁ¥¢Âºï
```sql
-- JSONBÂ≠óÊÆµÁöÑGINÁ¥¢Âºï
CREATE INDEX idx_agents_tools_gin ON agents USING GIN(tools);
CREATE INDEX idx_agents_capabilities_gin ON agents USING GIN(capabilities);
CREATE INDEX idx_tasks_tags_gin ON tasks USING GIN(tags);
CREATE INDEX idx_workflows_tags_gin ON workflows USING GIN(tags);
CREATE INDEX idx_executions_logs_gin ON executions USING GIN(logs);

-- ÁâπÂÆöJSONBË∑ØÂæÑÁ¥¢Âºï
CREATE INDEX idx_agents_llm_model ON agents((llm_config->>'model'));
CREATE INDEX idx_workflows_execution_mode ON workflows(execution_mode);
```

### 5. ÂÖ®ÊñáÊêúÁ¥¢Á¥¢Âºï
```sql
-- ÂÖ®ÊñáÊêúÁ¥¢Á¥¢Âºï
CREATE INDEX idx_agents_search ON agents USING GIN(
    to_tsvector('english', coalesce(name, '') || ' ' || coalesce(description, '') || ' ' || coalesce(role, ''))
);

CREATE INDEX idx_tasks_search ON tasks USING GIN(
    to_tsvector('english', coalesce(name, '') || ' ' || coalesce(description, ''))
);

CREATE INDEX idx_workflows_search ON workflows USING GIN(
    to_tsvector('english', coalesce(name, '') || ' ' || coalesce(description, ''))
);
```

---

## üîí Á∫¶ÊùüÂíåËß¶ÂèëÂô®

### 1. Ê£ÄÊü•Á∫¶Êùü
```sql
-- Áä∂ÊÄÅÊúâÊïàÊÄßÁ∫¶ÊùüÂ∑≤Âú®Ë°®ÂÆö‰πâ‰∏≠ÂåÖÂê´

-- È¢ùÂ§ñÁöÑ‰∏öÂä°ÈÄªËæëÁ∫¶Êùü
ALTER TABLE tasks ADD CONSTRAINT ck_tasks_retry_logic 
    CHECK (retry_count <= max_retries);

ALTER TABLE workflows ADD CONSTRAINT ck_workflows_version_format 
    CHECK (version ~ '^\d+\.\d+\.\d+$');
```

### 2. Ëß¶ÂèëÂô®ÂáΩÊï∞
```sql
-- Êõ¥Êñ∞Êó∂Èó¥Êà≥Ëß¶ÂèëÂô®ÂáΩÊï∞
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- ‰∏∫ÊâÄÊúâË°®ÂàõÂª∫Êõ¥Êñ∞Êó∂Èó¥Êà≥Ëß¶ÂèëÂô®
CREATE TRIGGER update_agents_updated_at BEFORE UPDATE ON agents
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_tasks_updated_at BEFORE UPDATE ON tasks
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_workflows_updated_at BEFORE UPDATE ON workflows
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_executions_updated_at BEFORE UPDATE ON executions
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### 3. ÁªüËÆ°‰ø°ÊÅØÊõ¥Êñ∞Ëß¶ÂèëÂô®
```sql
-- AgentÊâßË°åÁªüËÆ°Êõ¥Êñ∞ÂáΩÊï∞
CREATE OR REPLACE FUNCTION update_agent_execution_stats()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' AND NEW.execution_type = 'AGENT' THEN
        UPDATE agents SET total_executions = total_executions + 1
        WHERE id = NEW.agent_id;
    ELSIF TG_OP = 'UPDATE' AND NEW.execution_type = 'AGENT' THEN
        IF OLD.status != NEW.status THEN
            IF NEW.status = 'COMPLETED' THEN
                UPDATE agents SET 
                    successful_executions = successful_executions + 1,
                    avg_execution_time = (
                        avg_execution_time * (successful_executions - 1) + NEW.execution_time
                    ) / successful_executions
                WHERE id = NEW.agent_id;
            ELSIF NEW.status = 'FAILED' THEN
                UPDATE agents SET failed_executions = failed_executions + 1
                WHERE id = NEW.agent_id;
            END IF;
        END IF;
    END IF;
    RETURN COALESCE(NEW, OLD);
END;
$$ language 'plpgsql';

CREATE TRIGGER trigger_update_agent_stats
    AFTER INSERT OR UPDATE ON executions
    FOR EACH ROW EXECUTE FUNCTION update_agent_execution_stats();
```

---

## üîÑ Êï∞ÊçÆËøÅÁßªÁ≠ñÁï•

### 1. AlembicÈÖçÁΩÆ
```python
# alembic.ini ÈÖçÁΩÆ
[alembic]
script_location = migrations
prepend_sys_path = .
version_path_separator = os
sqlalchemy.url = postgresql://user:password@localhost/crewai_studio

[post_write_hooks]
hooks = black
black.type = console_scripts
black.entrypoint = black
black.options = -l 79 REVISION_SCRIPT_FILENAME
```

### 2. ÂàùÂßãËøÅÁßªËÑöÊú¨
```python
# migrations/versions/001_initial_schema.py
"""Initial schema

Revision ID: 001
Revises: 
Create Date: 2024-01-01 00:00:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

revision = '001'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    # ÂàõÂª∫agentsË°®
    op.create_table('agents',
        sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('updated_at', sa.TIMESTAMP(timezone=True), nullable=False),
        sa.Column('name', sa.VARCHAR(255), nullable=False),
        sa.Column('description', sa.TEXT(), nullable=True),
        # ... ÂÖ∂‰ªñÂ≠óÊÆµ
        sa.PrimaryKeyConstraint('id')
    )
    
    # ÂàõÂª∫ÂÖ∂‰ªñË°®...
    
    # ÂàõÂª∫Á¥¢Âºï
    op.create_index('idx_agents_status', 'agents', ['status'])
    # ... ÂÖ∂‰ªñÁ¥¢Âºï

def downgrade():
    op.drop_table('agents')
    # ... Âà†Èô§ÂÖ∂‰ªñË°®
```

### 3. Êï∞ÊçÆËøÅÁßªÊúÄ‰Ω≥ÂÆûË∑µ

#### ËøÅÁßªËÑöÊú¨ËßÑËåÉ
```python
# ËøÅÁßªËÑöÊú¨Ê®°Êùø
def upgrade():
    # 1. ÂàõÂª∫Êñ∞Ë°®
    # 2. Ê∑ªÂä†Êñ∞Âàó
    # 3. Êï∞ÊçÆËΩ¨Êç¢
    # 4. Âà†Èô§ÊóßÂàó
    # 5. ÂàõÂª∫Á¥¢Âºï
    # 6. Ê∑ªÂä†Á∫¶Êùü
    pass

def downgrade():
    # ÂèçÂêëÊìç‰Ωú
    pass
```

#### Â§ßÊï∞ÊçÆÈáèËøÅÁßªÁ≠ñÁï•
```python
# ÂàÜÊâπÂ§ÑÁêÜÂ§ßË°®ËøÅÁßª
def upgrade():
    # Ê∑ªÂä†Êñ∞Âàó
    op.add_column('large_table', sa.Column('new_column', sa.String(255)))
    
    # ÂàÜÊâπÊõ¥Êñ∞Êï∞ÊçÆ
    connection = op.get_bind()
    batch_size = 10000
    offset = 0
    
    while True:
        result = connection.execute(
            text(f"""
            UPDATE large_table 
            SET new_column = old_column 
            WHERE id IN (
                SELECT id FROM large_table 
                WHERE new_column IS NULL 
                LIMIT {batch_size}
            )
            """)
        )
        if result.rowcount == 0:
            break
        offset += batch_size
    
    # Ê∑ªÂä†ÈùûÁ©∫Á∫¶Êùü
    op.alter_column('large_table', 'new_column', nullable=False)
```

---

## üìä ÊÄßËÉΩ‰ºòÂåñ

### 1. Êü•ËØ¢‰ºòÂåñ
```sql
-- ‰ΩøÁî®EXPLAIN ANALYZEÂàÜÊûêÊü•ËØ¢ÊÄßËÉΩ
EXPLAIN ANALYZE SELECT * FROM tasks 
WHERE status = 'PENDING' AND priority > 5
ORDER BY created_at DESC LIMIT 10;

-- ‰ºòÂåñÂ∏∏ËßÅÊü•ËØ¢
-- 1. ÂàÜÈ°µÊü•ËØ¢‰ºòÂåñ
SELECT * FROM tasks 
WHERE created_at < '2024-01-01' 
ORDER BY created_at DESC 
LIMIT 20;

-- 2. ËÅöÂêàÊü•ËØ¢‰ºòÂåñ
SELECT 
    status, 
    COUNT(*) as count,
    AVG(execution_time) as avg_time
FROM executions 
WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY status;
```

### 2. ËøûÊé•Ê±†ÈÖçÁΩÆ
```python
# SQLAlchemyËøûÊé•Ê±†ÈÖçÁΩÆ
engine = create_engine(
    DATABASE_URL,
    pool_size=20,          # ËøûÊé•Ê±†Â§ßÂ∞è
    max_overflow=30,       # ÊúÄÂ§ßÊ∫¢Âá∫ËøûÊé•Êï∞
    pool_timeout=30,       # Ëé∑ÂèñËøûÊé•Ë∂ÖÊó∂Êó∂Èó¥
    pool_recycle=3600,     # ËøûÊé•ÂõûÊî∂Êó∂Èó¥
    pool_pre_ping=True,    # ËøûÊé•ÂâçpingÊµãËØï
    echo=False             # Áîü‰∫ßÁéØÂ¢ÉÂÖ≥Èó≠SQLÊó•Âøó
)
```

### 3. ÂàÜÂå∫Á≠ñÁï•
```sql
-- ÊåâÊó∂Èó¥ÂàÜÂå∫executionsË°®
CREATE TABLE executions_partitioned (
    LIKE executions INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- ÂàõÂª∫ÊúàÂ∫¶ÂàÜÂå∫
CREATE TABLE executions_2024_01 PARTITION OF executions_partitioned
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE executions_2024_02 PARTITION OF executions_partitioned
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

---

## üîê ÂÆâÂÖ®Á≠ñÁï•

### 1. Êï∞ÊçÆÂ∫ìÁî®Êà∑ÊùÉÈôê
```sql
-- ÂàõÂª∫Â∫îÁî®Áî®Êà∑
CREATE USER crewai_app WITH PASSWORD 'secure_password';

-- Êéà‰∫àÂøÖË¶ÅÊùÉÈôê
GRANT CONNECT ON DATABASE crewai_studio TO crewai_app;
GRANT USAGE ON SCHEMA public TO crewai_app;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO crewai_app;
GRANT USAGE ON ALL SEQUENCES IN SCHEMA public TO crewai_app;

-- ÂàõÂª∫Âè™ËØªÁî®Êà∑
CREATE USER crewai_readonly WITH PASSWORD 'readonly_password';
GRANT CONNECT ON DATABASE crewai_studio TO crewai_readonly;
GRANT USAGE ON SCHEMA public TO crewai_readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO crewai_readonly;
```

### 2. ÊïèÊÑüÊï∞ÊçÆÂ§ÑÁêÜ
```sql
-- ÊïèÊÑüÂ≠óÊÆµÂä†ÂØÜÂ≠òÂÇ®
-- ‰ΩøÁî®pgcryptoÊâ©Â±ï
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- Âä†ÂØÜÂ≠òÂÇ®Á§∫‰æã
CREATE TABLE secure_configs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    encrypted_value BYTEA, -- Âä†ÂØÜÂ≠òÂÇ®ÁöÑÂÄº
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- ÊèíÂÖ•Âä†ÂØÜÊï∞ÊçÆ
INSERT INTO secure_configs (name, encrypted_value) 
VALUES ('api_key', pgp_sym_encrypt('secret_api_key', 'encryption_key'));

-- Êü•ËØ¢Ëß£ÂØÜÊï∞ÊçÆ
SELECT name, pgp_sym_decrypt(encrypted_value, 'encryption_key') as value 
FROM secure_configs WHERE name = 'api_key';
```

---

## üìã Â§á‰ªΩÂíåÊÅ¢Â§ç

### 1. Â§á‰ªΩÁ≠ñÁï•
```bash
#!/bin/bash
# Êï∞ÊçÆÂ∫ìÂ§á‰ªΩËÑöÊú¨

DB_NAME="crewai_studio"
BACKUP_DIR="/backups/postgresql"
DATE=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="${BACKUP_DIR}/${DB_NAME}_${DATE}.sql"

# ÂàõÂª∫Â§á‰ªΩÁõÆÂΩï
mkdir -p $BACKUP_DIR

# ÊâßË°åÂ§á‰ªΩ
pg_dump -h localhost -U postgres -d $DB_NAME > $BACKUP_FILE

# ÂéãÁº©Â§á‰ªΩÊñá‰ª∂
gzip $BACKUP_FILE

# Âà†Èô§7Â§©ÂâçÁöÑÂ§á‰ªΩ
find $BACKUP_DIR -name "${DB_NAME}_*.sql.gz" -mtime +7 -delete

echo "Backup completed: ${BACKUP_FILE}.gz"
```

### 2. ÊÅ¢Â§çÁ≠ñÁï•
```bash
#!/bin/bash
# Êï∞ÊçÆÂ∫ìÊÅ¢Â§çËÑöÊú¨

BACKUP_FILE=$1
DB_NAME="crewai_studio"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# ÂÅúÊ≠¢Â∫îÁî®ÊúçÂä°
sudo systemctl stop crewai-studio

# Âà†Èô§Áé∞ÊúâÊï∞ÊçÆÂ∫ì
dropdb -h localhost -U postgres $DB_NAME

# ÂàõÂª∫Êñ∞Êï∞ÊçÆÂ∫ì
createdb -h localhost -U postgres $DB_NAME

# ÊÅ¢Â§çÊï∞ÊçÆ
if [[ $BACKUP_FILE == *.gz ]]; then
    gunzip -c $BACKUP_FILE | psql -h localhost -U postgres -d $DB_NAME
else
    psql -h localhost -U postgres -d $DB_NAME < $BACKUP_FILE
fi

# ÂêØÂä®Â∫îÁî®ÊúçÂä°
sudo systemctl start crewai-studio

echo "Database restored from: $BACKUP_FILE"
```

---

## üìà ÁõëÊéßÂíåÁª¥Êä§

### 1. ÊÄßËÉΩÁõëÊéßÊü•ËØ¢
```sql
-- ÊÖ¢Êü•ËØ¢ÁõëÊéß
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    rows
FROM pg_stat_statements 
ORDER BY total_time DESC 
LIMIT 10;

-- Ë°®Â§ßÂ∞èÁõëÊéß
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Á¥¢Âºï‰ΩøÁî®ÊÉÖÂÜµ
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes 
ORDER BY idx_scan DESC;
```

### 2. ÂÆöÊúüÁª¥Êä§‰ªªÂä°
```sql
-- ÂÆöÊúüÊ∏ÖÁêÜËøáÊúüÊï∞ÊçÆ
DELETE FROM executions 
WHERE created_at < CURRENT_DATE - INTERVAL '90 days'
AND status IN ('COMPLETED', 'FAILED');

-- Êõ¥Êñ∞Ë°®ÁªüËÆ°‰ø°ÊÅØ
ANALYZE;

-- ÈáçÂª∫Á¥¢ÂºïÔºàÂ¶ÇÈúÄË¶ÅÔºâ
REINDEX INDEX CONCURRENTLY idx_executions_created_at;

-- Ê∏ÖÁêÜÊó†Áî®ÁöÑÊâßË°åÊó•Âøó
UPDATE executions 
SET logs = '[]' 
WHERE created_at < CURRENT_DATE - INTERVAL '30 days'
AND jsonb_array_length(logs) > 100;
```

---

## üìù ÊÄªÁªì

Êú¨Êï∞ÊçÆÂ∫ìËÆæËÆ°ÊñáÊ°£Êèê‰æõ‰∫Ü CrewAI Studio È°πÁõÆÁöÑÂÆåÊï¥Êï∞ÊçÆÂ∫ìÊû∂ÊûÑÔºåÂåÖÊã¨Ôºö

1. **ÂÆåÊï¥ÁöÑÊï∞ÊçÆÊ®°ÂûãÂÆö‰πâ** - Ê∂µÁõñÊâÄÊúâÊ†∏ÂøÉÂÆû‰ΩìÂíåÂÖ≥Á≥ª
2. **‰ºòÂåñÁöÑÁ¥¢ÂºïÁ≠ñÁï•** - ÊèêÂçáÊü•ËØ¢ÊÄßËÉΩ
3. **ÂÆåÂñÑÁöÑÁ∫¶ÊùüÂíåËß¶ÂèëÂô®** - ‰øùËØÅÊï∞ÊçÆÂÆåÊï¥ÊÄß
4. **ÁÅµÊ¥ªÁöÑËøÅÁßªÁ≠ñÁï•** - ÊîØÊåÅÂπ≥ÊªëÁöÑÁâàÊú¨ÂçáÁ∫ß
5. **ÂÖ®Èù¢ÁöÑÂÆâÂÖ®Êé™ÊñΩ** - ‰øùÊä§ÊïèÊÑüÊï∞ÊçÆ
6. **ÂèØÈù†ÁöÑÂ§á‰ªΩÊÅ¢Â§ç** - Á°Æ‰øùÊï∞ÊçÆÂÆâÂÖ®
7. **ÊåÅÁª≠ÁöÑÁõëÊéßÁª¥Êä§** - ‰øùÊåÅÁ≥ªÁªüÂÅ•Â∫∑

ËØ•ËÆæËÆ°ÊîØÊåÅÈ´òÂπ∂Âèë„ÄÅÂ§ßÊï∞ÊçÆÈáèÁöÑÁîü‰∫ßÁéØÂ¢É‰ΩøÁî®Ôºå‰∏∫ CrewAI Studio ÁöÑÁ®≥ÂÆöËøêË°åÊèê‰æõ‰∫ÜÂùöÂÆûÁöÑÊï∞ÊçÆÂü∫Á°Ä„ÄÇ